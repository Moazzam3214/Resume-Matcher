{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21aeba69",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c179be0",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pymupdf\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import os\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "import dotenv\n",
        "import google.generativeai as genai\n",
        "import openpyxl\n",
        "from openpyxl.styles import Font\n",
        "import pandas as pd\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8fdcf3f",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "055348f2",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aadbe454",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "SKILLS = [\n",
        "    'python', 'docker', 'machine learning', 'fastapi', 'aws', 'nlp', 'tensorflow',\n",
        "    'pytorch', 'scikit-learn', 'pandas', 'numpy', 'matplotlib', 'seaborn', 'sql',\n",
        "    'nosql', 'mongodb', 'postgresql', 'redis', 'git', 'github', 'gitlab',\n",
        "    'ci/cd', 'jenkins', 'travis ci', 'github actions', 'aws s3', 'aws ec2',\n",
        "    'aws rds', 'aws lambda', 'aws dynamodb', 'kubernetes', 'docker-compose',\n",
        "    'api development', 'restful apis', 'graphql', 'microservices',\n",
        "    'data analysis', 'data visualization', 'big data', 'spark', 'hadoop',\n",
        "    'kafka', 'etl', 'data warehousing', 'cloud computing', 'azure', 'gcp',\n",
        "    'deep learning', 'neural networks', 'computer vision', 'object detection',\n",
        "    'image processing', 'natural language processing', 'sentiment analysis',\n",
        "    'topic modeling', 'transformers', 'bert', 'gpt', 'time series analysis',\n",
        "    'statistical modeling', 'a/b testing', 'model deployment', 'mlops',\n",
        "    'airflow', ' prefect', ' dvc', ' mlflow', ' unit testing', ' integration testing',\n",
        "    'system design', 'agile', 'scrum', 'linux', 'bash', 'shell scripting',\n",
        "    'virtualization', 'vmware', 'virtualbox', 'containerization', ' terraform',\n",
        "    'ansible', ' puppet', ' chef', ' javascript', ' html', ' css', ' react', ' angular',\n",
        "    'vue.js', 'node.js', 'django', 'flask', 'ruby on rails', ' java', ' c++', ' c#',\n",
        "    'go', 'scala', ' r', ' excel', ' google sheets', ' tableau', ' power bi',\n",
        "    ' spark streaming', ' hadoop hdfs', ' yarn', ' zookeeper', ' cassandra', ' neo4j',\n",
        "    ' rabbitmq', ' aws eks', ' aws ecr', ' azure aks', ' gcp gke', ' openshift',\n",
        "    ' helm', ' prometheus', ' grafana', ' elasticsearch', ' logstash', ' kibana',\n",
        "    ' serverless', ' aws step functions', ' azure functions', ' gcp cloud functions',\n",
        "    ' blockchain', ' smart contracts', ' solidity', ' web3', ' cybersecurity',\n",
        "    ' network security', ' penetration testing', ' ethical hacking', ' cryptography',\n",
        "    ' devops', ' site reliability engineering', ' sre', ' monitoring', ' logging',\n",
        "    'incident response', 'disaster recovery', ' business intelligence',\n",
        "    ' data mining', ' feature engineering', ' model evaluation', ' model selection',\n",
        "    ' hyperparameter tuning', ' cross-validation', ' regularization', ' boosting',\n",
        "    ' bagging', ' random forests', ' support vector machines', ' k-means',\n",
        "    ' dbscan', ' hierarchical clustering', ' pca', ' t-sne', ' umap', ' recommender systems',\n",
        "    ' reinforcement learning', ' gan', ' autoencoders', ' lstm', ' gru',\n",
        "    ' convolutional neural networks', ' cnn', ' recurrent neural networks', ' rnn',\n",
        "    ' transfer learning', ' fine-tuning', ' attention mechanisms', ' transformers',\n",
        "    ' federated learning', ' differential privacy', ' explainable ai', ' xai',\n",
        "    ' responsible ai', ' ai ethics', ' fairness', ' bias detection', ' bias mitigation',\n",
        "    ' ai governance', ' regulatory compliance', ' gdpr', ' ccpa',\n",
        "    ' project management', ' leadership', ' communication', ' collaboration',\n",
        "    ' problem solving', ' critical thinking', ' adaptability', ' continuous learning',\n",
        "    ' mentoring', ' technical writing', ' presentation skills'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84a0fa8c",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text):\n",
        "    return model.encode(text, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f008a14",
      "metadata": {
        "id": "e40f886d",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    text = \"\"\n",
        "    with pymupdf.open(pdf_path) as pdf:\n",
        "        for page in pdf:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def get_resume_embeddings(pdf_path):\n",
        "    raw_text = extract_text_from_pdf(pdf_path)\n",
        "    cleaned_text = clean_text(raw_text)\n",
        "    embeddings = get_embedding(cleaned_text)\n",
        "    return embeddings, cleaned_text\n",
        "\n",
        "\n",
        "def extract_skills(text, skill_list):\n",
        "    text = text.lower()\n",
        "    return set(skill for skill in skill_list if skill in text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0042b131",
      "metadata": {
        "id": "45316627",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# spaCy matcher setup\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "patterns = [nlp(skill) for skill in SKILLS]\n",
        "matcher.add(\"SKILLS\", patterns)\n",
        "\n",
        "def extract_skills_with_matcher(text):\n",
        "    doc = nlp(text.lower())\n",
        "    matches = matcher(doc)\n",
        "    return set(doc[start:end].text.lower() for _, start, end in matches)\n",
        "\n",
        "def semantic_skill_match(text, skills, threshold=0.6):\n",
        "    text_embedding = model.encode(text, convert_to_tensor=True)\n",
        "    matched = set()\n",
        "    for skill in skills:\n",
        "        skill_embedding = model.encode(skill, convert_to_tensor=True)\n",
        "        sim = util.cos_sim(text_embedding, skill_embedding).item()\n",
        "        if sim > threshold:\n",
        "            matched.add(skill)\n",
        "    return matched\n",
        "\n",
        "def extract_skills_combined(text, all_skills=SKILLS, threshold=0.6):\n",
        "    exact_matches = extract_skills_with_matcher(text)\n",
        "    unmatched_skills = set(all_skills) - exact_matches\n",
        "    semantic_matches = semantic_skill_match(text, unmatched_skills, threshold)\n",
        "    return exact_matches.union(semantic_matches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d615ed",
      "metadata": {
        "id": "f1d00798",
        "language": "python"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1768666876.py, line 1)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mjob_description_text =\u001b[39m\n                           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "job_description_text = \"\"\"  Some job description here\"\"\"\n",
        "job_skills = extract_skills(job_description_text, SKILLS)\n",
        "job_description_embeddings = get_embedding(job_description_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36245237",
      "metadata": {
        "id": "4705acb6",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "resume_folder = \"resumes/\"\n",
        "resume_files = [f for f in os.listdir(resume_folder) if f.endswith('.pdf')]\n",
        "\n",
        "for resume_file in resume_files:\n",
        "    resume_path = os.path.join(resume_folder, resume_file)\n",
        "    resume_embeddings = get_resume_embeddings(resume_path)\n",
        "    resume_skills = extract_skills(resume_embeddings[1], SKILLS)\n",
        "\n",
        "    missing_skills = job_skills - resume_skills\n",
        "\n",
        "    if missing_skills:\n",
        "        feedback = f\"Missing skills: {', '.join(missing_skills)}. Consider adding experience or projects related to them.\"\n",
        "    else:\n",
        "        feedback = f\"Great! Your resume covers all the key skills for this job.\"\n",
        "\n",
        "    similarity_score = util.pytorch_cos_sim(\n",
        "        resume_embeddings[0], job_description_embeddings).item()\n",
        "\n",
        "    print(\n",
        "        f\"Resume: {resume_file}, Similarity Score: {similarity_score:.4f}, Feedback: {feedback}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5afc0ba",
      "metadata": {
        "id": "1787b3fe",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def get_feedback_via_gemini(resume_text, job_text):\n",
        "    prompt = f\"\"\"\n",
        "You are an AI resume reviewer. The job description is:\n",
        "\n",
        "{job_text}\n",
        "\n",
        "The resume content is:\n",
        "\n",
        "{resume_text}\n",
        "\n",
        "Analyze how well the resume matches the job. What key skills or qualifications are missing? Suggest 2–3 improvements to make the resume a better match.\n",
        "\n",
        "Keep it brief and useful.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4814cba1",
      "metadata": {
        "id": "f6d6a314",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for resume_file in resume_files:\n",
        "    resume_path = os.path.join(resume_folder, resume_file)\n",
        "    resume_embeddings = get_resume_embeddings(resume_path)\n",
        "    resume_skills = extract_skills(resume_embeddings[1], SKILLS)\n",
        "    missing_skills = job_skills - resume_skills\n",
        "    matched_skills = resume_skills & job_skills\n",
        "    similarity_score = util.pytorch_cos_sim(\n",
        "        resume_embeddings[0], job_description_embeddings).item()\n",
        "    gemini_feedback = get_feedback_via_gemini(\n",
        "        resume_embeddings[1], job_description_text)\n",
        "    results.append({\n",
        "        'candidate': resume_file,\n",
        "        'match_score': round(similarity_score, 2),\n",
        "        'skills_matched': (\", \".join(matched_skills) if matched_skills else \"None\").title(),\n",
        "        'skills_missing': (\", \".join(missing_skills) if missing_skills else \"None\").title(),\n",
        "        'feedback': gemini_feedback.replace('*', '')\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83a337bb",
      "metadata": {
        "id": "9e482414",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "434d48f3",
      "metadata": {
        "id": "3c0b0c51",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert results to DataFrame and sort by match_score descending\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results_sorted = df_results.sort_values(by='match_score', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197ea131",
      "metadata": {
        "id": "63dad925",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "df_results_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fa5130",
      "metadata": {
        "id": "520ae17c",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def save_results_to_excel(results=results, filename=\"ranked_resumes.xlsx\"):\n",
        "    wb = openpyxl.Workbook()\n",
        "    ws = wb.active\n",
        "    ws.title = \"Resume Ranking\"\n",
        "\n",
        "    # Headers\n",
        "    headers = [\n",
        "        \"Candidate\", \"Match Score (%)\", \"Skills Matched\", \"Missing Skills\", \"LLM Feedback\"]\n",
        "    ws.append(headers)\n",
        "\n",
        "    # Bold headers\n",
        "    for cell in ws[1]:\n",
        "        cell.font = Font(bold=True)\n",
        "\n",
        "    # Data rows\n",
        "    for res in results:\n",
        "        ws.append([\n",
        "            res[\"candidate\"],\n",
        "            round(res[\"match_score\"] * 100, 2),\n",
        "            res[\"skills_matched\"],\n",
        "            res[\"skills_missing\"],\n",
        "            res[\"feedback\"]\n",
        "        ])\n",
        "\n",
        "    wb.save(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e95666",
      "metadata": {
        "id": "26191b2f",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "save_results_to_excel(df_results_sorted.to_dict('records'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38e4bbe3",
        "language": "python"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
